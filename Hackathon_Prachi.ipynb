{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e02b58-0e7f-4706-bb2a-f536c51b99f2",
   "metadata": {},
   "source": [
    "## Hackathon - Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970198d-d458-41f3-8d2d-4d3f3ee89067",
   "metadata": {},
   "source": [
    "Name - Prachi Chavan <br>\n",
    "Pga 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1629f27-01ed-4aaf-9fb2-fa01624d302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to corrected_algoparams.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Corrected JSON data\n",
    "hackathon_json = {\n",
    "    \"session_name\": \"test\",\n",
    "    \"session_description\": \"test\",\n",
    "    \"design_state_data\": {\n",
    "        \"session_info\": {\n",
    "            \"project_id\": \"1\",\n",
    "            \"experiment_id\": \"kkkk-11\",\n",
    "            \"dataset\": \"iris_modified.csv\",\n",
    "            \"session_name\": \"test\",\n",
    "            \"session_description\": \"test\"\n",
    "        },\n",
    "        \"target\": {\n",
    "            \"prediction_type\": \"Classification\",\n",
    "            \"target\": \"species\",\n",
    "            \"type\": \"classification\",\n",
    "            \"partitioning\": True\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"policy\": \"Split the dataset\",\n",
    "            \"time_variable\": \"sepal_length\",\n",
    "            \"sampling_method\": \"No sampling(whole data)\",\n",
    "            \"split\": \"Randomly\",\n",
    "            \"k_fold\": False,\n",
    "            \"train_ratio\": 0.8,\n",
    "            \"random_seed\": 10\n",
    "        },\n",
    "        \"feature_handling\": {\n",
    "            \"sepal_length\": {\n",
    "                \"feature_name\": \"sepal_length\",\n",
    "                \"is_selected\": True,\n",
    "                \"feature_variable_type\": \"numerical\",\n",
    "                \"feature_details\": {\n",
    "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
    "                    \"rescaling\": \"No rescaling\",\n",
    "                    \"make_derived_feats\": False,\n",
    "                    \"missing_values\": \"Impute\",\n",
    "                    \"impute_with\": \"Average of values\"\n",
    "                }\n",
    "            },\n",
    "            \"sepal_width\": {\n",
    "                \"feature_name\": \"sepal_width\",\n",
    "                \"is_selected\": True,\n",
    "                \"feature_variable_type\": \"numerical\",\n",
    "                \"feature_details\": {\n",
    "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
    "                    \"rescaling\": \"No rescaling\",\n",
    "                    \"make_derived_feats\": False,\n",
    "                    \"missing_values\": \"Impute\",\n",
    "                    \"impute_with\": \"Average of values\"\n",
    "                }\n",
    "            },\n",
    "            \"petal_length\": {\n",
    "                \"feature_name\": \"petal_length\",\n",
    "                \"is_selected\": True,\n",
    "                \"feature_variable_type\": \"numerical\",\n",
    "                \"feature_details\": {\n",
    "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
    "                    \"rescaling\": \"No rescaling\",\n",
    "                    \"make_derived_feats\": False,\n",
    "                    \"missing_values\": \"Impute\",\n",
    "                    \"impute_with\": \"Average of values\"\n",
    "                }\n",
    "            },\n",
    "            \"petal_width\": {\n",
    "                \"feature_name\": \"petal_width\",\n",
    "                \"is_selected\": False,\n",
    "                \"feature_variable_type\": \"numerical\",\n",
    "                \"feature_details\": {\n",
    "                    \"numerical_handling\": \"Keep as regular numerical feature\",\n",
    "                    \"rescaling\": \"No rescaling\",\n",
    "                    \"make_derived_feats\": False,\n",
    "                    \"missing_values\": \"Impute\",\n",
    "                    \"impute_with\": \"Average of values\"\n",
    "                }\n",
    "            },\n",
    "            \"species\": {\n",
    "                \"feature_name\": \"species\",\n",
    "                \"is_selected\": True,\n",
    "                \"feature_variable_type\": \"text\",\n",
    "                \"feature_details\": {\n",
    "                    \"text_handling\": \"Tokenize and hash\",\n",
    "                    \"hash_columns\": 0\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"algorithms\": {\n",
    "            \"RandomForestClassifier\": {\n",
    "                \"model_name\": \"Random Forest Classifier\",\n",
    "                \"is_selected\": True,\n",
    "                \"min_trees\": 10,\n",
    "                \"max_trees\": 30,\n",
    "                \"feature_sampling_statergy\": \"Default\",\n",
    "                \"min_depth\": 20,\n",
    "                \"max_depth\": 30,\n",
    "                \"min_samples_per_leaf_min_value\": 5,\n",
    "                \"min_samples_per_leaf_max_value\": 50,\n",
    "                \"parallelism\": 0\n",
    "            },\n",
    "            \"RandomForestRegressor\": {\n",
    "                \"model_name\": \"Random Forest Regressor\",\n",
    "                \"is_selected\": False,\n",
    "                \"min_trees\": 10,\n",
    "                \"max_trees\": 20,\n",
    "                \"feature_sampling_statergy\": \"Default\",\n",
    "                \"min_depth\": 20,\n",
    "                \"max_depth\": 25,\n",
    "                \"min_samples_per_leaf_min_value\": 5,\n",
    "                \"min_samples_per_leaf_max_value\": 10,\n",
    "                \"parallelism\": 0\n",
    "            },\n",
    "            \"LinearRegression\": {\n",
    "                \"model_name\": \"LinearRegression\",\n",
    "                \"is_selected\": False,\n",
    "                \"parallelism\": 2,\n",
    "                \"min_iter\": 30,\n",
    "                \"max_iter\": 50,\n",
    "                \"min_regparam\": 0.5,\n",
    "                \"max_regparam\": 0.8,\n",
    "                \"min_elasticnet\": 0.5,\n",
    "                \"max_elasticnet\": 0.8\n",
    "            },\n",
    "            \"LogisticRegression\": {\n",
    "                \"model_name\": \"LogisticRegression\",\n",
    "                \"is_selected\": False,\n",
    "                \"parallelism\": 2,\n",
    "                \"min_iter\": 30,\n",
    "                \"max_iter\": 50,\n",
    "                \"min_regparam\": 0.5,\n",
    "                \"max_regparam\": 0.8,\n",
    "                \"min_elasticnet\": 0.5,\n",
    "                \"max_elasticnet\": 0.8\n",
    "            },\n",
    "            \"RidgeRegression\": {\n",
    "                \"model_name\": \"RidgeRegression\",\n",
    "                \"is_selected\": False,\n",
    "                \"regularization_term\": \"Specify values to test\",\n",
    "                \"min_iter\": 30,\n",
    "                \"max_iter\": 50,\n",
    "                \"min_regparam\": 0.5,\n",
    "                \"max_regparam\": 0.8\n",
    "            },\n",
    "            \"LassoRegression\": {\n",
    "                \"model_name\": \"Lasso Regression\",\n",
    "                \"is_selected\": False,\n",
    "                \"regularization_term\": \"Specify values to test\",\n",
    "                \"min_iter\": 30,\n",
    "                \"max_iter\": 50,\n",
    "                \"min_regparam\": 0.5,\n",
    "                \"max_regparam\": 0.8\n",
    "            },\n",
    "            \"ElasticNetRegression\": {\n",
    "                \"model_name\": \"Lasso Regression\",\n",
    "                \"is_selected\": False,\n",
    "                \"regularization_term\": \"Specify values to test\",\n",
    "                \"min_iter\": 30,\n",
    "                \"max_iter\": 50,\n",
    "                \"min_regparam\": 0.5,\n",
    "                \"max_regparam\": 0.8,\n",
    "                \"min_elasticnet\": 0.5,\n",
    "                \"max_elasticnet\": 0.8\n",
    "            },\n",
    "            \"xg_boost\": {\n",
    "                \"model_name\": \"XG Boost\",\n",
    "                \"is_selected\": False,\n",
    "                \"use_gradient_boosted_tree\": True,\n",
    "                \"dart\": True,\n",
    "                \"tree_method\": \"\",\n",
    "                \"random_state\": 0,\n",
    "                \"max_num_of_trees\": 0,\n",
    "                \"early_stopping\": True,\n",
    "                \"early_stopping_rounds\": 2,\n",
    "                \"max_depth_of_tree\": [56, 89],\n",
    "                \"learningRate\": [89, 76],\n",
    "                \"l1_regularization\": [77],\n",
    "                \"l2_regularization\": [78],\n",
    "                \"gamma\": [68],\n",
    "                \"min_child_weight\": [67],\n",
    "                \"sub_sample\": [67],\n",
    "                \"col_sample_by_tree\": [67],\n",
    "                \"replace_missing_values\": False,\n",
    "                \"parallelism\": 0\n",
    "            },\n",
    "            \"DecisionTreeRegressor\": {\n",
    "                \"model_name\": \"Decision Tree\",\n",
    "                \"is_selected\": False,\n",
    "                \"min_depth\": 4,\n",
    "                \"max_depth\": 7,\n",
    "                \"use_gini\": False,\n",
    "                \"use_entropy\": True,\n",
    "                \"min_samples_per_leaf\": [12, 6],\n",
    "                \"use_best\": True,\n",
    "                \"use_random\": True\n",
    "            },\n",
    "            \"DecisionTreeClassifier\": {\n",
    "                \"model_name\": \"Decision Tree\",\n",
    "                \"is_selected\": True,\n",
    "                \"min_depth\": 4,\n",
    "                \"max_depth\": 7,\n",
    "                \"use_gini\": False,\n",
    "                \"use_entropy\": True,\n",
    "                \"min_samples_per_leaf\": [12, 6],\n",
    "                \"use_best\": True,\n",
    "                \"use_random\": False\n",
    "            },\n",
    "            \"SVM\": {\n",
    "                \"model_name\": \"Support Vector Machine\",\n",
    "                \"is_selected\": False,\n",
    "                \"linear_kernel\": True,\n",
    "                \"rep_kernel\": True,\n",
    "                \"polynomial_kernel\": True,\n",
    "                \"sigmoid_kernel\": True,\n",
    "                \"c_value\": [566, 79],\n",
    "                \"auto\": True,\n",
    "                \"scale\": True,\n",
    "                \"custom_gamma_values\": True,\n",
    "                \"tolerance\": 7,\n",
    "                \"max_iterations\": 7\n",
    "            },\n",
    "            \"KNN\": {\n",
    "                \"model_name\": \"KNN\",\n",
    "                \"is_selected\": False,\n",
    "                \"k_value\": [78],\n",
    "                \"distance_weighting\": True,\n",
    "                \"neighbour_finding_algorithm\": \"Automatic\",\n",
    "                \"random_state\": 0,\n",
    "                \"p_value\": 0\n",
    "            },\n",
    "            \"neural_network\": {\n",
    "                \"model_name\": \"Neural Network\",\n",
    "                \"is_selected\": False,\n",
    "                \"hidden_layer_sizes\": [67, 89],\n",
    "                \"activation\": \"\",\n",
    "                \"alpha_value\": 0,\n",
    "                \"max_iterations\": 0,\n",
    "                \"convergence_tolerance\": 0,\n",
    "                \"early_stopping\": True,\n",
    "                \"solver\": \"ADAM\",\n",
    "                \"shuffle_data\": True,\n",
    "                \"initial_learning_rate\": 0,\n",
    "                \"automatic_batching\": True,\n",
    "                \"beta_1\": 0,\n",
    "                \"beta_2\": 0,\n",
    "                \"epsilon\": 0,\n",
    "                \"power_t\": 0,\n",
    "                \"momentum\": 0,\n",
    "                \"use_nesterov_momentum\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "json_string = json.dumps(hackathon_json)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open(\"corrected_algoparams.json\", \"w\") as file:\n",
    "    file.write(json_string)\n",
    "\n",
    "print(\"JSON data has been written to corrected_algoparams.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03e6d57-26fa-4683-b206-820776011bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Load the Dataset\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Exploratory Data Analysis (EDA)\n",
    "def explore_data(dataset):\n",
    "    print(\"Dataset Info:\")\n",
    "    print(dataset.info())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(dataset.head())\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(dataset.describe())\n",
    "\n",
    "# Step 3: Preprocessing\n",
    "def preprocess_data(X_train, X_test):\n",
    "    # 1. Impute missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    # 2. Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Step 4: Split the Data\n",
    "def split_data(dataset, target_variable, test_size, random_seed):\n",
    "    X = dataset.drop(columns=[target_variable])\n",
    "    y = dataset[target_variable]\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca148a2-8ee4-4b64-b09f-d41a8d1231e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Evaluation Report for RandomForestClassifier:\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, r2_score, mean_squared_error\n",
    "\n",
    "# Step 1: Loading the JSON data\n",
    "with open(\"corrected_algoparams.json\", \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Step 2: Loading the Iris Modified dataset\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Step 3: Data preprocessing\n",
    "def preprocess_dataset(dataset):\n",
    "    X = dataset.drop(columns=[\"species\"])  #\"species\" is the target variable\n",
    "    y = dataset[\"species\"]\n",
    "    \n",
    "    # Split dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Imputing the missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Step 4: Identifying selected models from JSON data\n",
    "def identify_selected_models(json_data):\n",
    "    selected_models = {}\n",
    "    algorithms = json_data[\"design_state_data\"][\"algorithms\"]\n",
    "    \n",
    "    for algorithm_name, details in algorithms.items():\n",
    "        if details[\"is_selected\"]:\n",
    "            selected_models[algorithm_name] = details\n",
    "    \n",
    "    return selected_models\n",
    "\n",
    "# Step 5: hyperparameters for selected models\n",
    "def extract_hyperparameters(selected_models):\n",
    "    hyperparameters = {}\n",
    "    \n",
    "    for algorithm_name, details in selected_models.items():\n",
    "        if algorithm_name == \"RandomForestClassifier\":\n",
    "            hyperparameters[algorithm_name] = {\n",
    "                'n_estimators': [int(details[\"min_trees\"]), int(details[\"max_trees\"])],\n",
    "                'max_depth': [int(details[\"min_depth\"]), int(details[\"max_depth\"])],\n",
    "                'min_samples_leaf': [details[\"min_samples_per_leaf_min_value\"], details[\"min_samples_per_leaf_max_value\"]]\n",
    "            }\n",
    "        elif algorithm_name == \"SVM\":\n",
    "            hyperparameters[algorithm_name] = {\n",
    "                'C': [float(val) for val in details[\"c_value\"]],\n",
    "                'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "            }\n",
    "        elif algorithm_name == \"KNN\":\n",
    "            hyperparameters[algorithm_name] = {\n",
    "                'n_neighbors': [int(val) for val in details[\"k_value\"]],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'p': [1, 2]  # Manhattan or Euclidean distance\n",
    "            }\n",
    "        elif algorithm_name == \"LogisticRegression\":\n",
    "            hyperparameters[algorithm_name] = {\n",
    "                'C': [float(val) for val in details[\"min_regparam\"]],\n",
    "                'solver': ['liblinear', 'lbfgs', 'newton-cg']\n",
    "            }\n",
    "        \n",
    "    \n",
    "    return hyperparameters\n",
    "\n",
    "# Step 6: Building and training selected models with hyperparameter tuning\n",
    "def build_and_train_models(selected_models, hyperparameters, X_train, y_train):\n",
    "    trained_models = {}\n",
    "    \n",
    "    for algorithm_name, params in hyperparameters.items():\n",
    "        if algorithm_name == \"RandomForestClassifier\":\n",
    "            rf = RandomForestClassifier(random_state=42)\n",
    "            grid_search = GridSearchCV(estimator=rf, param_grid=params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            trained_models[algorithm_name] = grid_search.best_estimator_\n",
    "        elif algorithm_name == \"SVM\":\n",
    "            svm = SVC()\n",
    "            grid_search = GridSearchCV(estimator=svm, param_grid=params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            trained_models[algorithm_name] = grid_search.best_estimator_\n",
    "        elif algorithm_name == \"KNN\":\n",
    "            knn = KNeighborsClassifier()\n",
    "            grid_search = GridSearchCV(estimator=knn, param_grid=params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            trained_models[algorithm_name] = grid_search.best_estimator_\n",
    "        elif algorithm_name == \"LogisticRegression\":\n",
    "            lr = LogisticRegression()\n",
    "            grid_search = GridSearchCV(estimator=lr, param_grid=params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            trained_models[algorithm_name] = grid_search.best_estimator_\n",
    "\n",
    "    \n",
    "    return trained_models\n",
    "\n",
    "# Step 7: Evaluating trained models\n",
    "def evaluate_models(trained_models, X_test, y_test):\n",
    "    for algorithm_name, model in trained_models.items():\n",
    "        print(f\"Evaluation Report for {algorithm_name}:\")\n",
    "        if \"Classifier\" in algorithm_name:\n",
    "            y_pred = model.predict(X_test)\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "        else:  # Regression model\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            adj_r2 = 1 - (1 - r2) * ((len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1))\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            print(f\"R-squared: {r2:.4f}\")\n",
    "            print(f\"Adjusted R-squared: {adj_r2:.4f}\")\n",
    "            print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #  Load the Iris Modified dataset\n",
    "    dataset = load_dataset(\"iris_modified.csv\")\n",
    "    \n",
    "    #  Train-test split\n",
    "    X_train, X_test, y_train, y_test = preprocess_dataset(dataset)\n",
    "    \n",
    "    # Identify selected models from JSON data\n",
    "    selected_models = identify_selected_models(json_data)\n",
    "    \n",
    "    # Extract hyperparameters for selected models\n",
    "    hyperparameters = extract_hyperparameters(selected_models)\n",
    "    \n",
    "    #  Build and train selected models with hyperparameter tuning\n",
    "    trained_models = build_and_train_models(selected_models, hyperparameters, X_train, y_train)\n",
    "    \n",
    "    # Evaluate trained models\n",
    "    evaluate_models(trained_models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf8305-00bd-42fc-90c2-da8d4e664603",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a476756b-9918-4c9a-b51e-9c17b699a94d",
   "metadata": {},
   "source": [
    "Random Forest gave the best accuracy hence that is what has been selected and the model selected was the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7e0b4-a3da-4687-bfe0-d56ce9a2161b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
